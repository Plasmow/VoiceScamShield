<!doctype html>
<html>
<head>
  <meta charset="utf-8">
  <title>Voice Scam Shield - Prototype (Patched with File Streaming)</title>
  <style>
    body{font-family: Arial; padding:20px}
    #log{white-space:pre-wrap; background:#f6f6f6; padding:10px; height:260px; overflow:auto}
    #status{margin-top:10px}
    .risk{font-weight:bold}
    #reportArea{background:#fff9c4;padding:10px;margin-top:10px}
  </style>
</head>
<body>
  <h2>Voice Scam Shield — Prototype</h2>
  <p>Choose a call ID, then either start mic capture or send a WAV file directly to the backend as the caller.</p>
  Call ID: <input id="callId" value="demo1">
  <button id="startBtn">Start Mic</button>
  <button id="stopBtn" disabled>Stop</button>
  <label>Speaker: 
    <select id="speakerSel">
      <option value="caller">caller</option>
      <option value="user">user</option>
    </select>
  </label>
  <br><br>
  Upload WAV (16kHz mono recommended): 
  <input type="file" id="fileInput">
  <button id="sendFile">Send file to backend as caller</button>
  <h4>Live analysis</h4>
  <div id="log"></div>
  <div id="status">Risk score: <span id="riskScore">0.00</span> (<span id="riskLabel">safe</span>)</div>
  <div id="reportArea"><button id="downloadReport" disabled>Download Report (JSON)</button></div>

<script>
let ws;
let mediaStream;
let processor;
let audioCtx;
let sourceNode;
let sendInterval = 1000;
let buffer = [];
let sending = false;
let segments = [];
let riskThreshold = 0.75;

function log(msg){
  const el = document.getElementById('log');
  el.textContent = (new Date()).toLocaleTimeString()+" - "+msg+"\n"+el.textContent;
}

function floatTo16BitPCM(float32Array){
  const l = float32Array.length;
  const buf = new ArrayBuffer(l*2);
  const view = new DataView(buf);
  let offset = 0;
  for (let i=0;i<l;i++){
    let s = Math.max(-1, Math.min(1, float32Array[i]));
    view.setInt16(offset, s < 0 ? s*0x8000 : s*0x7FFF, true);
    offset+=2;
  }
  return new Uint8Array(buf);
}

async function start(){
  const callId = document.getElementById('callId').value || 'demo1';
  try {
    ws = new WebSocket("ws://localhost:8000/ws/" + callId);
  } catch (err) {
    log("❌ Error creating WebSocket: " + err);
    return;
  }
  ws.onopen = ()=>{ log('✅ WebSocket connected for call '+callId); };
  ws.onerror = ()=>{ log("❌ WebSocket error - check backend is running on localhost:8000"); };
  ws.onmessage = (ev)=>{
    const m = JSON.parse(ev.data);
    if (m.type==='analysis'){ handleAnalysis(m); }
    else if (m.type==='report'){ log('REPORT generated: '+JSON.stringify(m.report)); document.getElementById('downloadReport').disabled=false; window.latestReport=m.report;}
    else { log('MSG: '+ev.data);}
  };
  ws.onclose = ()=>{ log('WebSocket closed'); };

  try {
    audioCtx = new (window.AudioContext||window.webkitAudioContext)({sampleRate:16000});
    mediaStream = await navigator.mediaDevices.getUserMedia({audio:true});
  } catch (err) {
    log("❌ Microphone access error: " + err.message);
    return;
  }

  sourceNode = audioCtx.createMediaStreamSource(mediaStream);
  processor = audioCtx.createScriptProcessor(4096,1,1);
  sourceNode.connect(processor);
  processor.connect(audioCtx.destination);
  processor.onaudioprocess = (e)=>{
    const data = e.inputBuffer.getChannelData(0);
    buffer.push(new Float32Array(data));
  };

  sending = true;
  sendLoop(callId);
  document.getElementById('startBtn').disabled = true;
  document.getElementById('stopBtn').disabled = false;
}

async function sendLoop(callId){
  while(sending){
    await new Promise(r=>setTimeout(r, sendInterval));
    if (buffer.length===0) continue;
    let len=0; for (let b of buffer) len+=b.length;
    let tmp = new Float32Array(len); let off=0; for (let b of buffer){ tmp.set(b,off); off+=b.length; }
    buffer=[];
    const pcm = floatTo16BitPCM(tmp);
    const b64 = btoa(String.fromCharCode(...pcm));
    const speaker = document.getElementById('speakerSel').value;
    ws.send(JSON.stringify({type:'chunk', speaker: speaker, timestamp_ms: Date.now(), audio_chunk: b64}));
    log('Sent chunk ('+speaker+') from mic');
  }
}

function stop(){
  sending = false;
  if (processor){ processor.disconnect(); processor=null; }
  if (sourceNode){ sourceNode.disconnect(); sourceNode=null; }
  if (mediaStream){ mediaStream.getTracks().forEach(t=>t.stop()); }
  if (ws && ws.readyState===1){ ws.send(JSON.stringify({type:'end_call'})); ws.close(); }
  document.getElementById('startBtn').disabled = false;
  document.getElementById('stopBtn').disabled = true;
}

function handleAnalysis(m){
  log(`ANALYSIS [${m.speaker}] intent=${m.intent_label} (${m.intent_confidence}) spoof=${m.spoof_label} (${m.spoof_confidence}) text=${m.text}`);
  const intent_w = 0.7, spoof_w = 0.3;
  const risk = (m.intent_confidence*intent_w) + (m.spoof_confidence*spoof_w);
  document.getElementById('riskScore').textContent = risk.toFixed(2);
  const label = risk>riskThreshold ? 'scam' : (m.intent_label==='scam' ? 'suspicious' : 'safe');
  document.getElementById('riskLabel').textContent = label;
  segments.push(m);
}

document.getElementById('startBtn').onclick = start;
document.getElementById('stopBtn').onclick = stop;

document.getElementById('sendFile').onclick = async ()=>{
  const f = document.getElementById('fileInput').files[0];
  if (!f) return alert('Choose a WAV file first');
  if (!ws || ws.readyState !== 1){
    const callId = document.getElementById('callId').value || 'demo1';
    ws = new WebSocket("ws://localhost:8000/ws/" + callId);
    ws.onopen = ()=>{ log('✅ WebSocket connected for call '+callId); streamFile(f); };
    ws.onerror = ()=>{ log("❌ WebSocket error - check backend is running"); };
    ws.onmessage = (ev)=>{ const m = JSON.parse(ev.data); if (m.type==='analysis'){ handleAnalysis(m); } };
  } else {
    streamFile(f);
  }
};

async function streamFile(file){
  const arrayBuf = await file.arrayBuffer();
  const audioCtxFile = new (window.AudioContext||window.webkitAudioContext)();
  const audioBuf = await audioCtxFile.decodeAudioData(arrayBuf);
  const data = audioBuf.getChannelData(0); // mono channel
  const sampleRate = audioBuf.sampleRate;
  // Resample to 16kHz if needed
  let resampled = data;
  if (sampleRate !== 16000){
    const offlineCtx = new OfflineAudioContext(1, Math.floor(data.length * (16000/sampleRate)), 16000);
    const buffer = offlineCtx.createBuffer(1, data.length, sampleRate);
    buffer.copyToChannel(data, 0);
    const src = offlineCtx.createBufferSource();
    src.buffer = buffer;
    src.connect(offlineCtx.destination);
    src.start(0);
    resampled = await offlineCtx.startRendering().then(b => b.getChannelData(0));
  }
  const chunkSize = 16000; // 1s chunks
  for (let i = 0; i < resampled.length; i += chunkSize){
    const chunk = resampled.slice(i, i+chunkSize);
    const pcm = floatTo16BitPCM(chunk);
    const b64 = btoa(String.fromCharCode(...pcm));
    ws.send(JSON.stringify({type:'chunk', speaker:'caller', timestamp_ms: Date.now(), audio_chunk: b64}));
    log(`Sent file chunk ${i/chunkSize+1}`);
    await new Promise(r=>setTimeout(r, 200)); // small delay
  }
}
</script>
</body>
</html>
